"""
APIãƒ«ãƒ¼ã‚¿ãƒ¼
===========

ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹FastAPIãƒ«ãƒ¼ã‚¿ãƒ¼ã€‚
ä¸»è¦æ©Ÿèƒ½ï¼šç¿»è¨³ã€OCRã€RAGæ¤œç´¢ã€ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†

ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ï¼š
- /translate: å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³
- /translate_batch: ãƒãƒƒãƒç¿»è¨³ï¼ˆè¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆä¸€æ‹¬å‡¦ç†ï¼‰
- /rag: RAGæ¤œç´¢
- /normalize: ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–
- /ocr: PDF OCRå‡¦ç†
- /config: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨è¨­å®šå–å¾—
- /my-files: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å±¥æ­´
- /cleanup-old-files: å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
"""

from fastapi import APIRouter, HTTPException, UploadFile, File, Depends, Header
from pydantic import BaseModel
from .idp import get_authorized_user # ğŸ‘ˆ 1. å¯¼å…¥åˆšæ‰å†™çš„å®ˆé—¨äºº
from typing import Optional, List, Dict, Any
from app.services.llm import OptimizedLLMService
from app.services.rag import OptimizedRAGService
from app.services.normalize import NormalizeService
from app.services.dx_suite_ocr import DXSuiteOCRService
from app.services.blob_cache import BlobCacheService
from app.services.config import config
import logging
from app.routes.idp import verify_jwt

logger = logging.getLogger(__name__)

router = APIRouter(dependencies=[Depends(get_authorized_user)])

# Pydanticãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ»ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‹å®šç¾©ï¼‰

class TranslateRequest(BaseModel):
    """å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    text: str
    prompt: Optional[str] = None      # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆä»»æ„ï¼‰
    force_refresh: bool = False       # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡è¦–ãƒ•ãƒ©ã‚°

class TranslateBatchRequest(BaseModel):
    """ãƒãƒƒãƒç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆè¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆä¸€æ‹¬å‡¦ç†ï¼‰"""
    texts: List[str]
    force_refresh: bool = False

class TranslateResponse(BaseModel):
    """ç¿»è¨³ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    translation: str

class TranslateBatchResponse(BaseModel):
    """ãƒãƒƒãƒç¿»è¨³ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    translations: List[str]

class RAGRequest(BaseModel):
    """RAGæ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    text: str

class RAGResponse(BaseModel):
    """RAGæ¤œç´¢ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    result: list

class NormalizeRequest(BaseModel):
    """ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    text: str

class NormalizeResponse(BaseModel):
    """ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    normalized: str

class ConfigResponse(BaseModel):
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¨­å®šãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    frontend_config: Dict[str, Any]

class OCRResponse(BaseModel):
    """OCRå‡¦ç†ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    ocr_data: List[Dict[str, Any]]
    cache_hit: bool = False           # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆãƒ•ãƒ©ã‚°
    message: str = ""                 # å‡¦ç†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    processing_time_ms: Optional[float] = None  # å‡¦ç†æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰

@router.get("/config", response_model=ConfigResponse)
async def get_frontend_config():
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ã®è¨­å®šã‚’æä¾›ï¼ˆæ©Ÿå¯†æƒ…å ±ã¯é™¤ãï¼‰"""
    frontend_config = {
        # å¿…è¦ã«å¿œã˜ã¦ä»–ã®éæ©Ÿå¯†è¨­å®šã‚’è¿½åŠ 
        # "TEMPERATURE": config.TEMPERATURE,
        # "TOP_P": config.TOP_P,
        # "MAX_TOKENS": config.MAX_TOKENS,
    }
    return ConfigResponse(frontend_config=frontend_config)

@router.get("/me")
async def me(authorization: str = Header(None)):
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="missing token")
    token = authorization.split(" ", 1)[1]
    payload = verify_jwt(token)
    if not payload:
        raise HTTPException(status_code=401, detail="invalid token")
    return {"sub": payload.get("sub"), "email": payload.get("email"), "name": payload.get("name")}

@router.post("/translate", response_model=TranslateResponse)
async def translate(req: TranslateRequest):
    llm = OptimizedLLMService()
    rag = OptimizedRAGService()

    # RAG æ¤œç´¢
    rag_result = await rag.search(req.text)
    samples = rag.extract_samples(rag_result)

    # ãƒ•ãƒ­ãƒ³ãƒˆã‹ã‚‰promptãŒæ¥ã¦ã„ã‚Œã°ãã‚Œã‚’å„ªå…ˆã€ãªã‘ã‚Œã°æ—¢å®šã®çµ„ã¿ç«‹ã¦ã‚’ä½¿ç”¨
    prompt = req.prompt or llm.build_prompt(req.text, samples)
    translation = await llm.translate(prompt)
    if not translation:
        # å¤±æ•—æ™‚ã¯åŸæ–‡è¿”å´ï¼ˆJSç‰ˆä»•æ§˜ã«åˆã‚ã›ã‚‹ï¼‰
        translation = req.text
    return TranslateResponse(translation=translation)

@router.post("/translate_batch", response_model=TranslateBatchResponse)
async def translate_batch(req: TranslateBatchRequest):
    """æ€§èƒ½ã¨ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿ãƒãƒƒãƒç¿»è¨³API"""
    import asyncio
    from asyncio import Semaphore
    
    llm = OptimizedLLMService()
    rag = OptimizedRAGService()
    
    # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿ã‚»ãƒãƒ•ã‚©ï¼ˆä¿å®ˆçš„ã™ããšã€æ”»æ’ƒçš„ã™ããšï¼‰
    batch_semaphore = Semaphore(3)  # 2â†’3ã«èª¿æ•´
    
    async def translate_single_safe(text: str) -> str:
        async with batch_semaphore:
            try:
                # è»½å¾®ãªé…å»¶ã§ãƒ¬ãƒ¼ãƒˆåˆ¶é™å›é¿
                await asyncio.sleep(0.05)  # 0.1â†’0.05ã«çŸ­ç¸®
                
                # RAG æ¤œç´¢
                rag_result = await rag.search(text)
                samples = rag.extract_samples(rag_result)
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã¨ç¿»è¨³
                prompt = llm.build_prompt(text, samples)
                translation = await llm.translate(prompt)
                return translation or text
            except Exception as e:
                logger.warning(f"ãƒãƒƒãƒç¿»è¨³ã§ã®å€‹åˆ¥ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰: {e}")
                return text
    
    # åŠ¹ç‡åŒ–ã•ã‚ŒãŸä¸¦åˆ—ç¿»è¨³å®Ÿè¡Œ
    try:
        if len(req.texts) > 15:  # 10â†’15ã«èª¿æ•´ï¼ˆã‚ˆã‚Šå¤§ããªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼‰
            # å¤§é‡ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã¯ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            chunk_size = 8  # 5â†’8ã«èª¿æ•´ï¼ˆåŠ¹ç‡åŒ–ï¼‰
            chunks = [req.texts[i:i + chunk_size] for i in range(0, len(req.texts), chunk_size)]
            all_translations = []
            
            for chunk in chunks:
                chunk_translations = await asyncio.gather(*[translate_single_safe(text) for text in chunk])
                all_translations.extend(chunk_translations)
                # ãƒãƒ£ãƒ³ã‚¯é–“å¾…æ©Ÿã‚’çŸ­ç¸®
                await asyncio.sleep(0.3)  # 0.5â†’0.3ã«çŸ­ç¸®
            
            return TranslateBatchResponse(translations=all_translations)
        else:
            # å°‘é‡ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã¯é€šå¸¸å‡¦ç†
            translations = await asyncio.gather(*[translate_single_safe(text) for text in req.texts])
            return TranslateBatchResponse(translations=translations)
            
    except Exception as e:
        logger.error(f"ãƒãƒƒãƒç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
        return TranslateBatchResponse(translations=req.texts)

def parse_content_fields(content: str) -> tuple[str, str]:
    """
    contentãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰text_jaã¨text_enã‚’æŠ½å‡º
    
    Args:
        content: "text_ja: æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ\n\ntext_en: è‹±èªãƒ†ã‚­ã‚¹ãƒˆ\n..." å½¢å¼ã®æ–‡å­—åˆ—
                 ï¼ˆå¿…ãštext_jaã¨text_enã®ä¸¡æ–¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å‰æï¼‰
    
    Returns:
        tuple: (text_jaéƒ¨åˆ†, text_enéƒ¨åˆ†)
               text_enéƒ¨åˆ†ã¯æ–‡å­—åˆ—æœ«å°¾ã¾ã§æŠ½å‡ºã•ã‚Œã‚‹
    """
    text_ja = ""
    text_en = ""
    
    try:
        # text_jaéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆtext_en:ã¾ã§ï¼‰
        ja_start = content.find("text_ja:") + len("text_ja:")
        ja_end = content.find("text_en:")
        if ja_start > len("text_ja:") - 1 and ja_end > -1:
            text_ja = content[ja_start:ja_end].strip()
        
        # text_enéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆæœ«å°¾ã¾ã§ï¼‰
        en_start = content.find("text_en:") + len("text_en:")
        if en_start > len("text_en:") - 1:
            text_en = content[en_start:].strip()
    
    except Exception as e:
        logger.warning(f"contentè§£æã‚¨ãƒ©ãƒ¼: {e}, content: {content[:100]}...")
    
    return text_ja, text_en

@router.post("/rag", response_model=RAGResponse)
async def rag(req: RAGRequest):
    rag = OptimizedRAGService()
    result = await rag.search(req.text)
    if result is None:
        raise HTTPException(status_code=502, detail="RAG search failed")
    
    # ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æœŸå¾…å½¢å¼ã«å¤‰æ›
    search_results = result.get("result", {}).get("search_result", {})
    result_list = []
    if isinstance(search_results, dict):
        for key, value in search_results.items():
            if isinstance(value, dict):
                # ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯APIã®è¤‡æ•°ã®ã‚¹ã‚³ã‚¢ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ç¢ºèª
                score = (value.get("search_score") or 
                        value.get("reranker_score") or 
                        value.get("score") or 
                        0.0)
                
                # contentãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰text_jaã¨text_enã‚’æŠ½å‡º
                content = value.get("content", "")
                text_ja, text_en = parse_content_fields(content)
                
                # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãŒæœŸå¾…ã™ã‚‹æ§‹é€ ã«å¤‰æ›
                formatted_result = {
                    "body": {
                        "text": text_ja,           # contentã®text_jaéƒ¨åˆ† â†’ body.text
                        "data_source": text_en     # contentã®text_enéƒ¨åˆ† â†’ body.data_source
                    },
                    "_score": score  # search_scoreã€reranker_scoreã€ã¾ãŸã¯ score ã‚’ä½¿ç”¨
                }
                result_list.append(formatted_result)
    
    return RAGResponse(result=result_list)

@router.post("/normalize", response_model=NormalizeResponse)
async def normalize(req: NormalizeRequest):
    svc = NormalizeService()
    normalized = await svc.normalize(req.text)
    if not normalized:
        normalized = req.text
    return NormalizeResponse(normalized=normalized)

def get_user_id(x_ms_client_principal: Optional[str] = Header(None)) -> str:
    """
    èªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼ã®å–å¾—ï¼ˆç¾åœ¨ã¯ä½¿ç”¨ã—ã¦ã„ã¾ã›ã‚“ï¼‰
    ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†é›¢ãªã—ã®å…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ä¸­
    """
    # å…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ã®å›ºå®šID
    return "shared"

@router.post("/upload-pdf", response_model=OCRResponse)
async def upload_pdf(file: UploadFile = File(...)):
    """
    PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦OCRå‡¦ç†ã‚’å®Ÿè¡Œ
    Blob Storageã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ã—ã¦é‡è¤‡å‡¦ç†ã‚’å›é¿
    """
    import time
    start_time = time.time()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯
    if not file.content_type == "application/pdf":
        raise HTTPException(status_code=400, detail="PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™")
    
    try:
        # PDFãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿å–ã‚Š
        pdf_content = await file.read()
        
        # Blob ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        blob_cache = BlobCacheService()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
        file_hash = blob_cache.calculate_file_hash(pdf_content)
        logger.info(f"PDFå‡¦ç†é–‹å§‹: {file.filename}, ãƒãƒƒã‚·ãƒ¥: {file_hash}")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸOCRçµæœã‚’ç¢ºèªï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¯å›ºå®šå€¤ã§OKï¼‰
        cached_ocr = blob_cache.get_cached_ocr("shared", file_hash)
        if cached_ocr:
            processing_time = (time.time() - start_time) * 1000
            logger.info(f"OCRã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨: {file_hash} ({processing_time:.1f}ms)")
            return OCRResponse(
                ocr_data=cached_ocr.get("results", []),
                cache_hit=True,
                message=f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆï¼ é«˜é€Ÿå‡¦ç†å®Œäº† ({processing_time:.1f}ms)",
                processing_time_ms=processing_time
            )
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’Blob Storageã«ä¿å­˜
        blob_cache.save_pdf_file("shared", pdf_content, file.filename or "uploaded.pdf")
        
        # DX Suite OCRã‚µãƒ¼ãƒ“ã‚¹ã§OCRå‡¦ç†
        logger.info(f"DX Suite OCRå‡¦ç†ã‚’å®Ÿè¡Œ: {file_hash}")
        ocr_service = DXSuiteOCRService()
        ocr_result = await ocr_service.process_pdf(pdf_content, file.filename)
        
        if ocr_result is None:
            raise HTTPException(status_code=502, detail="OCRå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # OCRçµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        cache_data = {"results": ocr_result, "file_hash": file_hash, "filename": file.filename}
        blob_cache.save_ocr_result("shared", file_hash, cache_data)
        
        processing_time = (time.time() - start_time) * 1000
        logger.info(f"OCRçµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜: {file_hash} ({processing_time:.1f}ms)")
        
        return OCRResponse(
            ocr_data=ocr_result,
            cache_hit=False,
            message=f"æ–°è¦OCRå‡¦ç†å®Œäº† ({processing_time:.1f}ms) - æ¬¡å›ã¯é«˜é€Ÿã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨",
            processing_time_ms=processing_time
        )
        
    except Exception as e:
        logger.error(f"PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=f"PDFå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

@router.get("/my-files")
def get_my_files():
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
    """
    try:
        blob_cache = BlobCacheService()
        files = blob_cache.list_user_files("shared", limit=50)
        return {"files": files}
        
    except Exception as e:
        logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail="ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")

@router.delete("/cleanup-old-files")
def cleanup_old_files(days_old: int = 90):
    """
    å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ï¼ˆç®¡ç†ç”¨ï¼‰
    """
    try:
        blob_cache = BlobCacheService()
        deleted_count = blob_cache.cleanup_old_files("shared", days_old)
        return {"deleted_count": deleted_count, "message": f"{days_old}æ—¥ä»¥ä¸Šå‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’{deleted_count}å€‹å‰Šé™¤ã—ã¾ã—ãŸ"}
        
    except Exception as e:
        logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail="ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ")
